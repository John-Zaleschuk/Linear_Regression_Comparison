#==========================================#
# Authors: John Zaleschuk                  #
# Purpose: K-fold Linear regression to     #
#          predict final sales price on    #
#          housing data                    #
#==========================================#
import pandas as pd
import numpy as np
from sklearn.model_selection import KFold
from sklearn.linear_model import LinearRegression
from sklearn.linear_model import Ridge
from sklearn.linear_model import Lasso
from sklearn.metrics import root_mean_squared_error
import matplotlib.pyplot as plt

# Load the data set
raw_data = pd.read_csv('train.csv')

# Data Processing
# Calculate the total missing values for each column
total_missing = raw_data.isnull().sum()

# Select columns with less than 8 missing values
not_missing = raw_data.columns[total_missing < 8]

# Remove the columns with more than 8 missing values
# See program write-up for reasoning
data = raw_data[not_missing]

# Removal of one entry with missing electrical data
data = data.drop(data.loc[data['Electrical'].isnull()].index)

# Removal of 5 outliers that have sq footage over 4000
data = data[data.GrLivArea < 4000]

# using log to ensure high and low cost homes effect error equally
data.SalePrice = np.log1p(data.SalePrice)

# Changing categorial data to numerical data. 
data = pd.get_dummies(data)

# separate labels and features
Y = data.SalePrice
X = data.drop(columns=['SalePrice'])

# using for k-fold validation, random_state used to ensure repeatablility when shuffling
kf = KFold(shuffle=True, random_state = 8)

# printing table header, and column names with formatting
print("{:<15} {:<10} {:<10} {:<10}".format(" ","Linear", "Ridge", "Lasso"))
print("{:<15} {:<10} {:<10} {:<10}".format(" ","------", "-----", "-----"))

# From scikit, enumerate iterates over the elements generated by kf.split, 
# which is k pairs of (train, test) indices. 
for i, (train_index, test_index) in enumerate(kf.split(X)):
    
    # Define the arrays of data based on the divided indices.
    train_X = X.iloc[train_index]
    train_Y = Y.iloc[train_index]
    test_X = X.iloc[test_index]
    test_Y = Y.iloc[test_index]
    
    # Train the models using the training set.
    lineareg = LinearRegression().fit(train_X, train_Y)
    ridgereg = Ridge(alpha=0.4).fit(train_X, train_Y)
    lassoreg = Lasso(alpha=0.2).fit(train_X, train_Y)
    
    # Make predictions and use e to get original scale     
    lineareg_pred = np.expm1(lineareg.predict(test_X))
    ridgereg_pred = np.expm1(ridgereg.predict(test_X))
    lassoreg_pred = np.expm1(lassoreg.predict(test_X))
    original_Y = np.expm1(test_Y)
    
    # printing RMSE using the function from metrics
    print("{:<15} {:<10.5} {:<10.5} {:<10.5}"
      .format(f"\t Fold {i+1}\n\t ------\n\t  RMSE:", 
              f"{root_mean_squared_error(original_Y, lineareg_pred)}", 
              f"{root_mean_squared_error(original_Y, ridgereg_pred)}", 
              f"{root_mean_squared_error(original_Y, lassoreg_pred)}"))
    
    # Prints the scores into the table, formatted with column headers. 
    print("{:<15} {:<10.5} {:<10.5} {:<10.5}"
      .format(f"Accuracy Score:", 
              f"{lineareg.score(test_X, test_Y)}", 
              f"{ridgereg.score(test_X, test_Y)}", 
              f"{lassoreg.score(test_X, test_Y)}"),"\n\n")
    
    # prints the plots to compare the three different models used. 
    fig, axs = plt.subplots(1, 3, figsize=(18, 4))
    
    # linear regression plot
    axs[0].scatter(original_Y, lineareg_pred, c = 'red')
    axs[0].plot([min(original_Y), max(original_Y)], [min(original_Y), max(original_Y)], 'k--')
    axs[0].set_title('Linear Regression')
    
    # ridge regression plot
    axs[1].scatter(original_Y, ridgereg_pred)
    axs[1].plot([min(original_Y), max(original_Y)], [min(original_Y), max(original_Y)], 'k--')
    axs[1].set_title('Ridge Regression')
    
    # lasso regression plot
    axs[2].scatter(original_Y, lassoreg_pred, c = 'green')
    axs[2].plot([min(original_Y), max(original_Y)], [min(original_Y), max(original_Y)], 'k--')
    axs[2].set_title('Lasso Regression')
    
    for ax in axs:
        ax.set_xlabel('Actual Values')
        ax.set_ylabel('Predicted Values')
    
    plt.show()